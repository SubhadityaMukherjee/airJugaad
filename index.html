
<a href = "http://192.168.1.114:8080/html/ims.html">Images</a>
<a href = "http://192.168.1.114:8080/html/rec.html">Recieved</a>

<br>
<br>
<br>3
<br>
<br>new_tem
<br>
<br>
<br>
<br>
<br>
<br>https://www.kaggle.com/grassknoted/asl-alphabet
<br>https://www.kaggle.com/mostafaabla/garbage-classification
<br>https://www.kaggle.com/clorichel/boat-types-recognition
<br>https://www.kaggle.com/alxmamaev/flowers-recognition
<br>https://www.kaggle.com/moltean/fruits
<br>Kaggle links:
<br>
<br>
<br>and poster Ive been lazy but ill finish. I added most of the things.
<br>results you leave ill do that anyway I have them and screenshots and stuff
<br>
<br>thats it
<br>
<br>For efficientNet you can look at this : https://github.com/SubhadityaMukherjee/DLPapers/blob/master/Networks/EfficientNet/Efficient%20Net-d.pdf
<br>3. Find out some more about efficientNet and neural ode and write about it as well. 
<br>2. go to kaggle links and just write something about these datasets. no of classes, no of data , whats it doing etc etc
<br>1. Replace all places where we have said only ASL with these more datasets
<br>Bro what you need to do rn is.
<br>
<br>https://www.kaggle.com/grassknoted/asl-alphabet
<br>
<br>https://www.kaggle.com/moltean/fruits
<br>
<br>https://github.com/SubhadityaMukherjee/DLPapers/blob/master/Networks/EfficientNet/Efficient%20Net-d.pdf
<br>
<br>
<br>
<br>
<br>*.pdf
<br>
<br>significant difference exists among the different groups of tenure of service towards
<br>upon their tenure of service (F (4,439) =  2.241, p = .064).  This indicates that is no
<br>as contractor’s satisfaction is concerned, there exists no significant difference based
<br>Table 47 shows the results of one-way ANOVA.  The output implies that as far
<br>
<br>Hypothesis
<br>Table 45 Summarization of Results of H04
<br>in Table 45.
<br>null hypotheses H04 and acceptance of alternate hypothesis. The results are summarized
<br>different have the different opinion towards satisfaction.  This leads to the rejection of
<br>fabrication  (p=0.001). The  results  show  that  the  respondents  who  are  engaged  in
<br>perception of respondents from  Civil construction is different from Steel and Metal
<br>finishing and Civil construction is different (p= 0.043). The results also show that the
<br>industry in UAE. It is clear from Table 43 that the perception of respondents of Interior
<br>difference in respondents of group towards contractor’s satisfaction in B2B construction
<br>
<br>finishing, Civil construction, Façade and Steel and Metal fabrication) towards SATIS
<br>difference  significantly  exists  among  the  different  groups  (MEP  works,  Interior
<br>their engagement of organization (F (4,439) = 4.945, p = .001).  This indicates that is
<br>as contractor’s satisfaction is concerned, there exists significant difference based upon
<br>Table 43 shows the results of one-way ANOVA.  The output implies that as far
<br>
<br>leads to the acceptance of null hypothesis.
<br>no significant differences in their satisfaction in B2B construction industry in UAE. This
<br>
<br>no significant differences in their satisfaction in B2B construction industry in UAE. This
<br>interpreted that contractor’s role in Engineering services and Procurement services show
<br>
<br>
<br>
<br>
<br>
<br>Future 
<br>The experiments conclude that EODNet along with a better training strategy does infact give state of the art results on many datasets. 
<br>
<br>its application in solving differential equations. Applied Mathematics and Mechanics, 
<br>[9] Liu, Z., Yang, Y., & Cai, Q. (2019). Neural network as a function approximator and 
<br>neural flows. arXiv preprint arXiv:2003.08063.
<br>[8] Massaroli, S., Poli, M., Bin, M., Park, J., Yamashita, A., & Asama, H. (2020). Stable 
<br>on Machine Learning (pp. 11086-11095). PMLR.
<br>capabilities of neural ODEs and invertible residual networks. In International Conference 
<br>[7] Zhang, H., Gao, X., Unterman, J., & Arodz, T. (2020, November). Approximation 
<br>differential equations. arXiv preprint arXiv:1806.07366.
<br>[6] Chen, R. T., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018). Neural ordinary 
<br>constant weights. arXiv preprint arXiv:1906.12183.
<br>[5] Avelin, B., & Nyström, K. (2019). Neural ODEs as the deep limit of ResNets with 
<br>neural odes. arXiv preprint arXiv:2002.08071.
<br>[4] Massaroli, S., Poli, M., Park, J., Yamashita, A., & Asama, H. (2020). Dissecting 
<br>Networks, 16(5-6), 729-734.
<br>elliptic partial differential equation using radial basis function neural networks. Neural 
<br>[3] Jianyu, L., Siwei, L., Yingjian, Q., & Yaping, H. (2003). Numerical solution of 
<br>networks, 19(3), 539-543.
<br>[2] Filici, C. (2008). On a neural approximator to ODEs. IEEE transactions on neural 
<br>arXiv preprint arXiv:2001.04385.
<br>Ramadhan, A. (2020). Universal differential equations for scientific machine learning. 
<br>[1] Rackauckas, C., Ma, Y., Martensen, J., Warner, C., Zubov, K., Supekar, R., ... & 
<br>
<br>Neural Networks are important for th
<br>
<br>School of Computer Science & Engineering
<br>
<br>Designation: - Associate Profes
<br>Vijayarajan V
<br>
<br> Using EODNet for ASL 
<br>Dia Rule Discovery using Neural ODEs
<br>
<br>Dia Rule Discovery using Neural ODEs
<br>
<br>ule Disc
<br>
<br>learn.fit(10)
<br>
<br>np.transpose(learn.img_list[-1].cpu(), (1, 2, 0))
<br>
<br>astype('uint8')
<br>
<br>
<br>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
<br>
<br>[0,:,:,:]
<br>
<br>learn.model_G(noise)
<br>
<br>noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)
<br>
<br>train
<br>
<br>                self.model_D.eval()
<br>self.model_G.eval()
<br>
<br>self.model_G.eval()
<br>
<br>learn.fit(1)
<br>
<br>learn.plot_output()
<br>
<br>with torch.enable_grad():
<br>
<br>print(disc_real.requires_grad)
<br>
<br>print(self.loss_D.requires_grad)
<br>
<br>initialize_weights(critic)
<br>initialize_weights(gen)
<br>
<br>-torch.mean(gen_fake)
<br>
<br>-(torch.mean(critic_real) - torch.mean(critic_fake))
<br>
<br>cbfs
<br>
<br>learn.fit(3)
<br>
<br>AvgStatsGANCallback
<br>
<br>create_graph
<br>
<br>return -(torch.mean(x) - torch.mean(y))
<br>
<br>self.x = x
<br>
<br>    
<br>        return -torch.mean(x)
<br>    def forward(self,x):
<br>        self.x = x
<br>    def __init__(self,x):
<br>class genloss(nn.Module):
<br>
<br>return -torch.mean(x)
<br>
<br>RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
<br>
<br>
<br>torch.optim
<br>
<br>optim.RMSprop(gen.parameters(), lr=1e-2),
<br>
<br>optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)
<br>
<br>self.xb, self.yb
<br>
<br>Discriminator(3, 64),
<br>
<br>Generator(100, 3, 64)
<br>
<br>self.loss_func_G
<br>
<br>torch.mean(x)
<br>
<br>    return -torch.mean(x)
<br>def genloss(x):
<br>
<br>backward()
<br>
<br>self.loss_G
<br>
<br>loss_G
<br>
<br>zero_grad()
<br>
<br>-torch.mean(gen_fake)
<br>
<br>gen_fake = critic(fake).reshape(-1)
<br>
<br>self.clip_value
<br>
<br>self.model_D
<br>
<br>self.data.train_ds.x[0].size(1)
<br>
<br>                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)
<br>            for p in critic.parameters():
<br>            # clip critic weights between -0.01, 0.01
<br>
<br>            opt_critic.step()
<br>            loss_critic.backward(retain_graph=True)
<br>            critic.zero_grad()
<br>            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))
<br>            critic_fake = critic(fake).reshape(-1)
<br>            critic_real = critic(data).reshape(-1)
<br>            fake = gen(noise)
<br>            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)
<br>for _ in range(CRITIC_ITERATIONS):
<br>
<br>fixed_noise = torch.randn(32, Z_DIM, 1, 1)
<br>
<br>nn.BCELoss
<br>
<br>        n_critic=5,
<br>        clip_value=0.01,
<br>        latent_dim=100,
<br>        device="cuda:0",
<br>        cb_funcs=None,
<br>        cbs=None,
<br>        splitter=param_getter,
<br>        lr=1e-2,
<br>        opt_func_G=sgd_opt,
<br>        opt_func_D=sgd_opt,
<br>        loss_func_G,
<br>        loss_func_D,
<br>        data,
<br>        model_G,
<br>model_D,
<br>
<br>
<br>            nn.init.normal_(m.weight.data, 0.0, 0.02)
<br>        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
<br>    for m in model.modules():
<br>    # Initializes weights according to the DCGAN paper
<br>def initialize_weights(model):
<br>
<br>
<br>        return self.net(x)
<br>    def forward(self, x):
<br>
<br>        )
<br>            nn.ReLU(),
<br>            nn.BatchNorm2d(out_channels),
<br>            ),
<br>                bias=False,
<br>                padding,
<br>                stride,
<br>                kernel_size,
<br>                out_channels,
<br>                in_channels,
<br>            nn.ConvTranspose2d(
<br>        return nn.Sequential(
<br>    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
<br>
<br>        )
<br>            nn.Tanh(),
<br>            # Output: N x channels_img x 64 x 64
<br>            ),
<br>                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1
<br>            nn.ConvTranspose2d(
<br>            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32
<br>            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16
<br>            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8
<br>            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4
<br>            # Input: N x channels_noise x 1 x 1
<br>        self.net = nn.Sequential(
<br>        super(Generator, self).__init__()
<br>    def __init__(self, channels_noise, channels_img, features_g):
<br>class Generator(nn.Module):
<br>
<br>
<br>        return self.disc(x)
<br>    def forward(self, x):
<br>
<br>        )
<br>            nn.LeakyReLU(0.2),
<br>            nn.InstanceNorm2d(out_channels, affine=True),
<br>            ),
<br>                bias=False,
<br>                padding,
<br>                stride,
<br>                kernel_size,
<br>                out_channels,
<br>                in_channels,
<br>            nn.Conv2d(
<br>        return nn.Sequential(
<br>    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
<br>
<br>        )
<br>            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),
<br>            # After all _block img output is 4x4 (Conv2d below makes into 1x1)
<br>            self._block(features_d * 4, features_d * 8, 4, 2, 1),
<br>            self._block(features_d * 2, features_d * 4, 4, 2, 1),
<br>            self._block(features_d, features_d * 2, 4, 2, 1),
<br>            # _block(in_channels, out_channels, kernel_size, stride, padding)
<br>            nn.LeakyReLU(0.2),
<br>            ),
<br>                channels_img, features_d, kernel_size=4, stride=2, padding=1
<br>            nn.Conv2d(
<br>            # input: N x channels_img x 64 x 64
<br>        self.disc = nn.Sequential(
<br>        super(Discriminator, self).__init__()
<br>    def __init__(self, channels_img, features_d):
<br>class Discriminator(nn.Module):
<br>
<br>
<br>
<br>        self.logger(stats)
<br>        stats += [format_time(time.time() - self.start_time)]
<br>            stats += [f"{v:.6f}" for v in o.avg_stats]
<br>        for o in [self.train_stats, self.valid_stats]:
<br>        stats = [str(self.epoch)]
<br>    def after_epoch(self):
<br>
<br>            stats.accumulate(self.run)
<br>        with torch.no_grad():
<br>        stats = self.train_stats if self.in_train else self.valid_stats
<br>    def after_loss(self):
<br>
<br>        self.start_time = time.time()
<br>        self.valid_stats.reset()
<br>        self.train_stats.reset()
<br>    def begin_epoch(self):
<br>
<br>        self.logger(names)
<br>        )
<br>            + ["time"]
<br>            + [f"valid_{n}" for n in met_names]
<br>            + [f"train_{n}" for n in met_names]
<br>            ["epoch"]
<br>        names = (
<br>        ]
<br>            m.__name__ for m in self.train_stats.metrics
<br>        met_names = ["loss_D", "loss_G"] + [
<br>    def begin_fit(self):
<br>
<br>        )
<br>            metrics, False
<br>        self.train_stats, self.valid_stats = AvgStatsGAN(metrics, True), AvgStatsGAN(
<br>    def __init__(self, metrics):
<br>
<br>    """
<br>    Main callback for stats for GANS Used for the progress bar
<br>    """
<br>class AvgStatsGANCallback(Callback):
<br>
<br>
<br>            self.tot_mets[i] += m(run.pred, run.yb) * bn
<br>        for i, m in enumerate(self.metrics):
<br>        self.count += bn
<br>        self.tot_loss_D += run.loss_D.to(run.device) * bn
<br>        self.tot_loss_G += run.loss_G.to(run.device) * bn
<br>        #         print(run.loss_D)
<br>        bn = run.xb.shape[0]
<br>    def accumulate(self, run):
<br>
<br>        return f"{'train' if self.in_train else 'valid'}: {self.avg_stats}"
<br>            return ""
<br>        if not self.count:
<br>    def __repr__(self):
<br>
<br>        return [o / self.count for o in self.all_stats]
<br>    def avg_stats(self):
<br>    @property
<br>
<br>        return [self.tot_loss_G.item(), self.tot_loss_D.item()] + self.tot_mets
<br>    def all_stats(self):
<br>    @property
<br>
<br>        self.tot_mets = [0.0] * len(self.metrics)
<br>        self.tot_loss_G, self.tot_loss_D, self.count = 0.0, 0.0, 1
<br>    def reset(self):
<br>
<br>        self.metrics, self.in_train = listify(metrics), in_train
<br>    def __init__(self, metrics, in_train):
<br>
<br>    """
<br>    Store statistics of training
<br>    """
<br>class AvgStatsGAN:
<br>
<br>
<br>
<br>https://youtube.com/playlist?list=PL-AARxYB7ywwIVkd1JVL6q51psvveNu86
<br>
<br>https://youtu.be/1HHuLUUcn7s
<br>
<br>
<br>
<br>
<br>rm demos/*.py
<br>
<br>
<br>
<br>
<br>jupytext --to notebook "demo.py"
<br>
<br>0.4974
<br>
<br>2037.3209
<br>
<br>    print(model(x).shape)
<br>
<br>    ).to(device)
<br>        num_classes=num_classes,
<br>        version=version,
<br>    model = EfficientNet(
<br>    x = torch.randn((num_examples, 3, res, res)).to(device)
<br>    num_examples, num_classes = 4, 10
<br>    phi, res, drop_rate = phi_values[version]
<br>    version = "b0"
<br>device = "cuda" if torch.cuda.is_available() else "cpu"
<br>
<br>        return self.classifier(x.view(x.shape[0], -1))
<br>        x = self.pool(self.features(x))
<br>    def forward(self, x):
<br>
<br>        return nn.Sequential(*features)
<br>
<br>        )
<br>            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)
<br>        features.append(
<br>
<br>                in_channels = out_channels
<br>                )
<br>                    )
<br>                        padding=kernel_size//2, # if k=1:pad=0, k=3:pad=1, k=5:pad=2
<br>                        kernel_size=kernel_size,
<br>                        stride = stride if layer == 0 else 1,
<br>                        expand_ratio=expand_ratio,
<br>                        out_channels,
<br>                        in_channels,
<br>                    InvertedResidualBlock(
<br>                features.append(
<br>            for layer in range(layers_repeats):
<br>
<br>            layers_repeats = ceil(repeats * depth_factor)
<br>            out_channels = 4*ceil(int(channels*width_factor) / 4)
<br>        for expand_ratio, channels, repeats, stride, kernel_size in base_model:
<br>
<br>        in_channels = channels
<br>        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]
<br>        channels = int(32 * width_factor)
<br>    def create_features(self, width_factor, depth_factor, last_channels):
<br>
<br>        return width_factor, depth_factor, drop_rate
<br>        width_factor = beta ** phi
<br>        depth_factor = alpha ** phi
<br>        phi, res, drop_rate = phi_values[version]
<br>    def calculate_factors(self, version, alpha=1.2, beta=1.1):
<br>
<br>        )
<br>            nn.Linear(last_channels, num_classes),
<br>            nn.Dropout(dropout_rate),
<br>        self.classifier = nn.Sequential(
<br>        self.features = self.create_features(width_factor, depth_factor, last_channels)
<br>        self.pool = nn.AdaptiveAvgPool2d(1)
<br>        last_channels = ceil(1280 * width_factor)
<br>        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)
<br>        super(EfficientNet, self).__init__()
<br>    def __init__(self, version, num_classes):
<br>class EfficientNet(nn.Module):
<br>
<br>            return self.conv(x)
<br>        else:
<br>            return self.stochastic_depth(self.conv(x)) + inputs
<br>        if self.use_residual:
<br>
<br>        x = self.expand_conv(inputs) if self.expand else inputs
<br>    def forward(self, inputs):
<br>
<br>        return torch.div(x, self.survival_prob) * binary_tensor
<br>        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob
<br>
<br>            return x
<br>        if not self.training:
<br>    def stochastic_depth(self, x):
<br>
<br>        )
<br>            nn.BatchNorm2d(out_channels),
<br>            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),
<br>            SqueezeExcitation(hidden_dim, reduced_dim),
<br>            ),
<br>                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,
<br>            CNNBlock(
<br>        self.conv = nn.Sequential(
<br>
<br>            )
<br>                in_channels, hidden_dim, kernel_size=3, stride=1, padding=1,
<br>            self.expand_conv = CNNBlock(
<br>        if self.expand:
<br>
<br>        reduced_dim = int(in_channels / reduction)
<br>        self.expand = in_channels != hidden_dim
<br>        hidden_dim = in_channels * expand_ratio
<br>        self.use_residual = in_channels == out_channels and stride == 1
<br>        self.survival_prob = 0.8
<br>        super(InvertedResidualBlock, self).__init__()
<br>    ):
<br>            survival_prob=0.8, # for stochastic depth
<br>            reduction=4, # squeeze excitation
<br>            expand_ratio,
<br>            padding,
<br>            stride,
<br>            kernel_size,
<br>            out_channels,
<br>            in_channels,
<br>            self,
<br>    def __init__(
<br>class InvertedResidualBlock(nn.Module):
<br>
<br>
<br>        return x * self.se(x)
<br>    def forward(self, x):
<br>
<br>        )
<br>            nn.Sigmoid(),
<br>            nn.Conv2d(reduced_dim, in_channels, 1),
<br>            nn.SiLU(),
<br>            nn.Conv2d(in_channels, reduced_dim, 1),
<br>            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1
<br>        self.se = nn.Sequential(
<br>        super(SqueezeExcitation, self).__init__()
<br>    def __init__(self, in_channels, reduced_dim):
<br>class SqueezeExcitation(nn.Module):
<br>
<br>        return self.silu(self.bn(self.cnn(x)))
<br>    def forward(self, x):
<br>
<br>        self.silu = nn.SiLU() # SiLU <-> Swish
<br>        self.bn = nn.BatchNorm2d(out_channels)
<br>        )
<br>            bias=False,
<br>            groups=groups,
<br>            padding,
<br>            stride,
<br>            kernel_size,
<br>            out_channels,
<br>            in_channels,
<br>        self.cnn = nn.Conv2d(
<br>        super(CNNBlock, self).__init__()
<br>    ):
<br>            self, in_channels, out_channels, kernel_size, stride, padding, groups=1
<br>    def __init__(
<br>class CNNBlock(nn.Module):
<br>
<br>from math import ceil
<br>
<br>return width_factor, depth_factor, drop_rate
<br>
<br>depth_factor = alpha **phi
<br>
<br>        )
<br>            nn.Linear(last_channels, num_classes),
<br>            nn.Dropout(dropout_rate),
<br>        self.classifier = nn.Sequential(
<br>        self.features = self.create_features(width_factor, depth_factor, last_channels)
<br>        self.pool = nn.AdaptiveAvgPool2d(1)
<br>        last_channels = ceil(1280 * width_factor)
<br>        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)
<br>        super(EfficientNet, self).__init__()
<br>    def __init__(self, version, num_classes):
<br>class EfficientNet(nn.Module):
<br>
<br>
<br>CNNBlock(in_channels, hidden_dim, kernel_size=3, stride= 1, padding=1)
<br>
<br>        reduced_dim = int(in_channels / reduction)
<br>        self.expand = in_channels != hidden_dim
<br>        hidden_dim = in_channels * expand_ratio
<br>        self.use_residual = in_channels == out_channels and stride == 1
<br>        self.survival_prob = 0.8
<br>super(InvertedResidualBlock, self).__init__()
<br>
<br>    ):
<br>            survival_prob=0.8, # for stochastic depth
<br>            reduction=4, # squeeze excitation
<br>            expand_ratio,
<br>            padding,
<br>            stride,
<br>            kernel_size,
<br>            out_channels,
<br>            in_channels,
<br>            self,
<br>def __init__(
<br>
<br>
<br>
<br>web_dir
<br>
<br>in_channels,
<br>
<br>nn.Conv2d(in_channels, reduced_dim, 1),
<br>
<br>in_channels, out_channels, kernel_size, stride, padding, groups
<br>
<br>
<br>}
<br>    "b7": (6, 600, 0.5),
<br>    "b6": (5, 528, 0.5),
<br>    "b5": (4, 456, 0.4),
<br>    "b4": (3, 380, 0.4),
<br>    "b3": (2, 300, 0.3),
<br>    "b2": (1, 260, 0.3),
<br>    "b1": (0.5, 240, 0.2),
<br>    "b0": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi
<br>    # tuple of: (phi_value, resolution, drop_rate)
<br>phi_values = {
<br>
<br>]
<br>    [6, 320, 1, 1, 3],
<br>    [6, 192, 4, 2, 5],
<br>    [6, 112, 3, 1, 5],
<br>    [6, 80, 3, 2, 3],
<br>    [6, 40, 2, 2, 5],
<br>    [6, 24, 2, 2, 3],
<br>    [1, 16, 1, 1, 3],
<br>    # expand_ratio, channels, repeats, stride, kernel_size
<br>base_model = [
<br>
